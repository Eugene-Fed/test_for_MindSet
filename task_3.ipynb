{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dd470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6f1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import idx2numpy as idx\n",
    "import time\n",
    "\n",
    "# from matplotlib import pyplot as plt       # чтобы выводить промежуточные фото в jupyter\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "from datetime import datetime\n",
    "\n",
    "# Список всех настроечных параметров/констант\n",
    "WORK_DIR = 'pass_photos'\n",
    "TEMP_DIR = 'pass_temp'\n",
    "DATESET_IMG = r\"D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_images_100k.idx\"\n",
    "DATASET_CLS = r\"D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_classes_100k.idx\"\n",
    "MODEL_PATH = 'ru_emnist_letters_100k_b64_e30.h5'\n",
    "# TEST_FILE = 'pass_photos/1.jpeg'\n",
    "IMG_HEIGHT = 1000            # требуемый размер фото для нормализации всех изображений\n",
    "IMG_WIDTH = 600              # т.к. в задачу входит прочитать только ФИО, обрезаю серию/номер чтобы не усложнять распознавание\n",
    "INDENT_LEFT = 220            # обрезаем фото т.к. без него получается лучше разделить фото на куски текста\n",
    "INDENT_TOP = 40              # обрезаем лишнюю часть паспорта снизу\n",
    "INDENT_BOTTOM = 120          # обрезаем нижние поля\n",
    "SCALE_FACTOR = 8             # во сколько раз увеличиваем вырезанные слова для дальнейшей обработки букв\n",
    "DATASET_SYMBOL_SIZE = 28     # размер изображений в тренировочном датасете      \n",
    "LABELS = '0123456789АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "SYMBOLS_COUNT = len(LABELS)  # количество символов в датасете: 33 + 33 + 10 (заглавные, строчные, цифры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb30b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения списка файлов из каталога с фотографиями (как в task_1 и task_2)\n",
    "# TODO: переделать функцию, чтобы принимала в кач-ве параметра regex с перечислением искомых расширений файла\n",
    "def get_files(directory: str) -> list:\n",
    "    names = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            names.append(os.path.join(directory, filename))\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184a289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабирование изображения\n",
    "def scale_image(image, scale):     # принимаем объект изображения OpenCV\n",
    "    \n",
    "    # получаем текущий размер, вычисляем искомый и создаем измененное изображение\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    img_width = int(width * scale)\n",
    "    img_height = int(height * scale)\n",
    "    img = cv2.resize(image, (img_width, img_height))\n",
    "    #img = cv2.resize(image, (img_width, img_height), interpolation=cv2.INTER_CUBIC) # рекомендуют, но качество страдает\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756c6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - это не пригодилось. Зря переусложнено. Но возможно без него я и получаю ошибку при распознавании\n",
    "def normalize_img_size(image, size):\n",
    "        h, w = image.shape[0], image.shape[1]     # сначала передается высота, потом ширина\n",
    "        size_max = max(w, h)\n",
    "        letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "        if w > h:\n",
    "            y_pos = size_max//2 - h//2\n",
    "            letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
    "        elif w < h:\n",
    "            x_pos = size_max//2 - w//2\n",
    "            letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
    "        else:\n",
    "            letter_square = letter_crop\n",
    "\n",
    "        # Resize letter to 28x28 and add letter and its X-coordinate\n",
    "        letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40284c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация размеров фотографии паспорта и вырезка нужной части для обработки\n",
    "def cut_passport_info_area(image):     # принимаем объект изображения OpenCV\n",
    "    \n",
    "    # нормализуем фото к нужному размеру\n",
    "    old_height = image.shape[0]     # получаем исходную высоту\n",
    "    resize_scale = IMG_HEIGHT / old_height       # считаем коэффициент масштабирования изображения до требуемого\n",
    "    img = scale_image(image=image, scale=resize_scale)\n",
    "    new_width = img.shape[1]      # получаем новую ширину\n",
    "    \n",
    "    # обрезаем паспорт до страницы с фото\n",
    "    x0 = INDENT_LEFT                            # отступ слева, т.к. корочка и фото нам не важны\n",
    "    y0 = IMG_HEIGHT // 2 + INDENT_TOP           # обрезка сверху, т.к. верхняя страница с местом выдачи нам не важна \n",
    "    x1 = new_width if new_width < IMG_WIDTH else IMG_WIDTH   # обрезаем все лишнее справа, если есть разворот с пропиской\n",
    "    y1 = IMG_HEIGHT - INDENT_BOTTOM\n",
    "    img = img[y0:y1, x0:x1]              # сохраняем вырезанный кусок изображения для передачи\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c504ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка изображений для распознавания текста\n",
    "def normalize_color(image):         # принимаем объект изображения OpenCV\n",
    "    \n",
    "    # обесцвечиваем, если картинка цветная\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    # преобразуем в ЧБ\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Размытие для снижения количества шумов. Эксперимент показал, что без него буквы детектируются лучше\n",
    "    # blur = cv2.GaussianBlur(gray, (5,5), 0)         # коэффициент размытия подобран вручную\n",
    "    \n",
    "    # Очередность преобраозвания найдена опытным путем\n",
    "    kernel = np.ones((5,5), 'uint8')\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))  # не знаю в чем разница, но так работает хуже\n",
    "    \n",
    "    # В теории erode - делает буквы тоньше, а dilate - толще: https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html\n",
    "    img_block = cv2.erode(gray, kernel, iterations=1)   # Но на практике \"жирность\" букв при этой операции повышается\n",
    "    #img_block = cv2.dilate(img_block, kernel, iterations=1)  # А тут - наоборот\n",
    "    \n",
    "    # TODO - поиграться с настройками, чтобы выдавать на выход именно контраст. Сейчас это только для детекции границ букв\n",
    "    _, img_block = cv2.threshold(img_block, 0, 255, cv2.THRESH_OTSU, cv2.THRESH_BINARY_INV) # Повышаем контраст\n",
    "    img_block = cv2.morphologyEx(img_block, cv2.MORPH_OPEN, kernel, iterations=1) # Снижаем шум на фоне\n",
    "    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Попытка найти лучший вариант детекции и выходного изображения. Оставил для дальнейших тестов\n",
    "    # Grayscale, Gaussian blur, Otsu's threshold\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Morph open to remove noise and invert image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    erosion = cv2.erode(gray, kernel, iterations = 1)\n",
    "    dilation = cv2.dilate(gray, kernel, iterations = 1)\n",
    "    invert = 255 - closing\n",
    "    \n",
    "    # Повышение контраста\n",
    "    if len(image.shape) > 2:\n",
    "        imghsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        imghsv[:,:,2] = [[max(pixel - 25, 0) if pixel < 190 else min(pixel + 25, 255) for pixel in row] for row in imghsv[:,:,2]]\n",
    "        contrast = cv2.cvtColor(imghsv, cv2.COLOR_HSV2BGR)\n",
    "        gray_contrast = cv2.cvtColor(contrast, cv2.COLOR_BGR2GRAY)    # преобразуем в ЧБ\n",
    "        \n",
    "    # при коэффициенте 3 - лучше распознается Васлевский, при 5 - Соколов и Юмакаева\n",
    "    img_symbol = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 2)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_TOZERO+cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return img_block, gray      # Возвращаем контрастную картинку с разбивкой на блоки и простое ЧБ изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fd772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем элементы текста из изображения\n",
    "def search_blocks(image, limit: int, sort_by: str, sort_reverse=False):\n",
    "    #::limit:: - необходим чтобы указать на сколько мелкие символы нам не нужно распознавать\n",
    "    \n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    # получаем контуры больших пятен на изображении, внутри которых спрятан текст\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # другая вариация\n",
    "    \n",
    "    # print(f'Count of Block counoturs: {len(contours)}')\n",
    "    blocks = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        # print(\"R\", x, y, w, h, hierarchy[0][idx])\n",
    "        # hierarchy[i][0]: следующий контур текущего уровня\n",
    "        # hierarchy[i][1]: предыдущий контур текущего уровня\n",
    "        # hierarchy[i][2]: первый вложенный элемент\n",
    "        # hierarchy[i][3]: родительский элемент\n",
    "        # if hierarchy[0][idx][3] == 0:               # если элемент не является самым крупным\n",
    "        # cv2.rectangle(image, (x, y), (x + w, y + h), (70, 0, 0), 1) # для контрольной картинки\n",
    "        \n",
    "        if limit < h < height and limit < w < width:    # игнорируем маленькие блоки, а также блок размером с изображение\n",
    "            block = image[y:y + h, x:x + w]     # вырезаем найденный блок из изображения\n",
    "            \n",
    "            # сохраняем габариты и изображение блока в список блоков. Загоняем в словарь, чтобы проще сортировать\n",
    "            # todo: По 'x' мы определяем очередность букв, ведь чем \"левее буква\", тем меньше ее 'x'. Также можно по 'y'\n",
    "            blocks.append({'idx': idx, 'y': y, 'h': h, 'x': x, 'w': w, 'block': block})\n",
    "    \n",
    "    # Сортируем по нужному ключу: 'y' для вертикали или 'x' по горизонтали. Так же можно и по индексу или размерам\n",
    "    blocks.sort(key=lambda x: x.get(sort_by), reverse=sort_reverse)\n",
    "    # print(blocks)\n",
    "    return blocks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3051b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Если детектор букв выдает нам слишком \"широкий\" блок - значит он склеил несколько соседних букв.\n",
    "Это возможно по двум причинам:\n",
    "1. Плохое качество печати/изображения, тогда действительно соседние буквы сливаются даже для человеческого взгляда.\n",
    "2. Плохое качество фильтра определения границ букв. С этим еще нужно поработать - поковырять параметры в normalize_color()\n",
    "Выход - решать проблему математически (на вскидку). Если ширина больше высоты на определенную константу (подобрана руками)\n",
    "то делим изображение на расчетное количество элементов.\n",
    "Это не панацея, т.к. в зависимости от шрифта буква \"Ж\" может быть шире, чем сочетание \"СТ\". С английскими \"ij\" еще хуже.\n",
    "\"\"\"\n",
    "def cut_blocks(image):\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    C = 1.2       # просто коэффициент, рассчитанный на широкие буквы вроде Ж, М, Ш и т.д., чтобы их не резало\n",
    "    if width < height*C:\n",
    "        # print(f'One symbol is True')\n",
    "        return [image]\n",
    "    else:\n",
    "        #print(f'One symbol is FALSE')\n",
    "        result = []\n",
    "        y, h, = 0, height      # высота и верхняя точке среза - всегда неизменны\n",
    "        symbol_count = math.ceil(width / height)    # округляем символы до большего целого\n",
    "        symbol_width = math.floor(width / symbol_count)   # округляем ширину в пикселях до меньшего целого\n",
    "        \n",
    "        for i in range(symbol_count):\n",
    "            x = i * symbol_width\n",
    "            result.append(image[y:h, x:x+symbol_width])\n",
    "            # print(f'y = {y}, h = {h}, x = {x}, symbol_width = {x+symbol_width}, width = {width}')\n",
    "            # print(f'symbol {i} is:\\n{result[i]}')\n",
    "            \n",
    "        # print(f'Count of separeted symbols: {len(result)}')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e15fc",
   "metadata": {},
   "source": [
    "### Детекция данных из паспорта и сохранение фоток букв в файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c683ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pass_photos\\\\0.jpeg', 'pass_photos\\\\1.jpeg', 'pass_photos\\\\2.jpeg']\n"
     ]
    }
   ],
   "source": [
    "passports = get_files(WORK_DIR)\n",
    "print(passports[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23503b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def passport_data_parser(work_dir: str, count: int):\n",
    "    # Запускаем цикл по всем фото в рабочей папке\n",
    "    try:     # TODO добавить проверку на существование файла\n",
    "        passports = get_files(work_dir)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "        \n",
    "    export_words = []\n",
    "    count = min(count, len(passports))     # Что меньше - по такой индекс и забираем фотки (для тестов)\n",
    "    \n",
    "    for id_p, passport in enumerate(passports[:count]):     # идем по списку путей к изображениям (ограничив длину списка)\n",
    "        temp_dir = os.path.join(TEMP_DIR, str(id_p))\n",
    "        if not os.path.exists(temp_dir):\n",
    "            os.mkdir(temp_dir)                              # создаем папку для сохранения промежуточных картинок\n",
    "\n",
    "        print(f'==== Image {id_p}.jpg =====')\n",
    "        image = cut_passport_info_area(cv2.imread(passport))     # получаем кусок паспорта с ФИО\n",
    "        img_blocks, img_gray = normalize_color(image=image)      # img_gray используем для передачи дальше\n",
    "        \n",
    "        # TODO - убрать сохранение промежутоных файлов, они используются только для визуального контроля\n",
    "        cv2.imwrite(f'{TEMP_DIR}/{id_p}_blocs.jpg', img_blocks)\n",
    "        cv2.imwrite(f'{TEMP_DIR}/{id_p}_symbols.jpg', image)\n",
    "\n",
    "        words = search_blocks(image=img_blocks, limit=15, sort_by='y')   # ищем блоки на картинке с жирными буквами\n",
    "        # cv2.imshow('The First Word', words[0]['block'])\n",
    "        # cv2.waitKey(0)\n",
    "        # print(f'Count of words: {words}')\n",
    "\n",
    "        # получаем все обнаруженные слова из файла, в котором читаются символы\n",
    "        for id_w, word in enumerate(words[:3]):    # можно забирать только первые 3 слова ФИО\n",
    "            export_words.append([None])      # добавляем вложенный список для каждого слова\n",
    "            # из словаря обнаруженного блока текста забираем координаты и размер блока\n",
    "            y, h, x, w = word['y'], word['h'], word['x'], word['w']\n",
    "            img_word = img_gray[y:y + h, x:x + w]     # вырезаем слово из серой картинки по его координатам\n",
    "            # img_word = image[y:y + h, x:x + w]     # вариант с повышением контраста, поэкспериментировать\n",
    "            \n",
    "            img_word = scale_image(img_word, SCALE_FACTOR)   # увеличиваем изображение, чтобы детектировать буквы\n",
    "            cv2.imwrite(os.path.join(temp_dir, f'{id_w}.jpg'), img_word)   #сохраняем файлы только для контроля\n",
    "\n",
    "            word_blocks, word_text = normalize_color(image=img_word) # прогоняем через детектор увеличенное фото слова\n",
    "            #word_blocks, word_text = normalize_color(image=word_text)    # вариант с повышением контраста\n",
    "            symbols = search_blocks(image=word_blocks, limit=SCALE_FACTOR*10, sort_by='x')\n",
    "            # print(f'Count of symbols: {len(symbols)}')\n",
    "            \n",
    "            # TODO - частичный повтор кода. Придумать как переделать, чтобы не дублировать функционал\n",
    "            for id_s, symbol in enumerate(symbols):\n",
    "                # TODO - убрать сохранение промежутоных файлов, они используются только для визуального контроля\n",
    "                word_dir = os.path.join(temp_dir, str(id_w))     # создаем очередную вложенную папку для котроля\n",
    "                if not os.path.exists(word_dir):\n",
    "                    os.mkdir(word_dir)\n",
    "\n",
    "                y, h, x, w = symbol['y'], symbol['h'], symbol['x'], symbol['w']\n",
    "                img_symbol = word_text[y:y + h, x:x + w]\n",
    "                #cv2.imwrite(os.path.join(word_dir, f'{symbol[0]}-{e}.jpg'), img_symbol)\n",
    "\n",
    "                # Доп. проверка на случай, если буквы плохо отделились\n",
    "                for id_o, one_symbol in enumerate(cut_blocks(img_symbol)):\n",
    "                    # one_symbol = cv2.resize(one_symbol, (DATASET_SYMBOL_SIZE, DATASET_SYMBOL_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    one_symbol = cv2.resize(one_symbol, (DATASET_SYMBOL_SIZE, DATASET_SYMBOL_SIZE))\n",
    "                    cv2.imwrite(os.path.join(word_dir, f'{id_s}-{id_o}.jpg'), one_symbol)\n",
    "                    export_words[id_w].append(one_symbol)\n",
    "                    \n",
    "    return export_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c574a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Image 0.jpg =====\n",
      "==== Image 1.jpg =====\n",
      "==== Image 2.jpg =====\n",
      "==== Image 3.jpg =====\n",
      "==== Image 4.jpg =====\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "symbols = []\n",
    "symbols.append(passport_data_parser(work_dir=WORK_DIR, count=5))   # Для теста разбираем только 1 паспорт\n",
    "print(len(symbols[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24aaac0",
   "metadata": {},
   "source": [
    "### Готовим модель и train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8c953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подгатавливаем модель для распознавания букв из датасетов по аналогии с EMNIST\n",
    "def main_model(img_size, lb_count):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid',\n",
    "                            input_shape=(img_size, img_size, 1), activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(lb_count, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_int(labels=LABELS) -> dict:\n",
    "    label_nums = {}\n",
    "    for i, lab in enumerate(labels):\n",
    "        label_nums[lab] = i\n",
    "    print(label_nums)\n",
    "    return label_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae630dd1",
   "metadata": {},
   "source": [
    "## Загружаем датасет и разбиваем на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10173127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'А': 10, 'Б': 11, 'В': 12, 'Г': 13, 'Д': 14, 'Е': 15, 'Ё': 16, 'Ж': 17, 'З': 18, 'И': 19, 'Й': 20, 'К': 21, 'Л': 22, 'М': 23, 'Н': 24, 'О': 25, 'П': 26, 'Р': 27, 'С': 28, 'Т': 29, 'У': 30, 'Ф': 31, 'Х': 32, 'Ц': 33, 'Ч': 34, 'Ш': 35, 'Щ': 36, 'Ъ': 37, 'Ы': 38, 'Ь': 39, 'Э': 40, 'Ю': 41, 'Я': 42, 'а': 43, 'б': 44, 'в': 45, 'г': 46, 'д': 47, 'е': 48, 'ё': 49, 'ж': 50, 'з': 51, 'и': 52, 'й': 53, 'к': 54, 'л': 55, 'м': 56, 'н': 57, 'о': 58, 'п': 59, 'р': 60, 'с': 61, 'т': 62, 'у': 63, 'ф': 64, 'х': 65, 'ц': 66, 'ч': 67, 'ш': 68, 'щ': 69, 'ъ': 70, 'ы': 71, 'ь': 72, 'э': 73, 'ю': 74, 'я': 75}\n",
      "X_train: (75000, 28, 28)\n",
      "X_test: (25000, 28, 28)\n",
      "y_train: (75000,)\n",
      "y_test: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет Часть 1 / 2\n",
    "labels_comparison = labels_to_int()     # получаем сопоставление символа к коду из датасета\n",
    "labels_symbol = list(labels_comparison.keys())     # и получаем отдельно список по символам и кодам\n",
    "labels_class = list(labels_comparison.values())\n",
    "\n",
    "#TODO - попробовать сгенерить модель на ru-EMNIST вместо моего датасета!!!! Возможно проблема именно в нем\n",
    "# Загружаем датасеты картинок и их классов\n",
    "ds_images = idx.convert_from_file(DATESET_IMG)\n",
    "ds_classes = idx.convert_from_file(DATASET_CLS)\n",
    "\n",
    "# Разбиваем выборки на train, test\n",
    "# TODO переписать под train, test, validate\n",
    "X_train, X_test = np.split(ds_images, [int(.75*len(ds_images))])\n",
    "y_train, y_test = np.split(ds_classes, [int(.75*len(ds_classes))])\n",
    "\n",
    "#print(labels_symbol)\n",
    "#print(labels_class)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620d3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 28, 28, 1) (75000,) (25000, 28, 28, 1) (25000,) 76\n",
      "(75000, 76) (25000, 76)\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет Часть 2 / 2\n",
    "\n",
    "# зачем-то предлагают сделать решейп датасета картинок, добавляя к слою изображения еще одно измерение\n",
    "# такой же решейп предлагается для отправляемого в готовую модель изображения. хз надо ли это делать тут и там\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))   ### 1 Убрать решейп здесь и в функции predict_img()\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Это тупо уменьшаем выборку из датасетов в 10 раз\n",
    "#k = 10\n",
    "#X_train = X_train[:X_train.shape[0] // k]\n",
    "#y_train = y_train[:y_train.shape[0] // k]\n",
    "#X_test = X_test[:X_test.shape[0] // k]\n",
    "#y_test = y_test[:y_test.shape[0] // k]\n",
    "\n",
    "# Нормализация - ХЗ что такое, разобраться    \n",
    "X_train = X_train.astype(np.float32)           ### 333333333333333333333333333333333333333\n",
    "X_train /= 255.0\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_test /= 255.0\n",
    "\n",
    "# \"маска\" на которую будут созданы предсказание категорий\n",
    "#x_train_cat = keras.utils.to_categorical(y_train, len(labels_comparison))   ### !!! вероятно ошибка тут !!!!\n",
    "y_train_cat = keras.utils.to_categorical(y_train, len(labels_comparison))    ### Вот так распознавание работает!!!\n",
    "y_test_cat = keras.utils.to_categorical(y_test, len(labels_comparison))\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(labels_comparison))\n",
    "print(y_train_cat.shape, y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a74b07",
   "metadata": {},
   "source": [
    "## Обучаем модель на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff8226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1172/1172 [==============================] - 88s 75ms/step - loss: 4.1987 - accuracy: 0.0412 - val_loss: 4.0442 - val_accuracy: 0.0505 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 3.9818 - accuracy: 0.0614 - val_loss: 3.8763 - val_accuracy: 0.0505 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 3.8802 - accuracy: 0.0756 - val_loss: 3.7830 - val_accuracy: 0.1384 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 3.8068 - accuracy: 0.0950 - val_loss: 3.6930 - val_accuracy: 0.2033 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 3.7247 - accuracy: 0.1226 - val_loss: 3.5953 - val_accuracy: 0.2761 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 3.6298 - accuracy: 0.1566 - val_loss: 3.4823 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 3.5196 - accuracy: 0.1976 - val_loss: 3.3514 - val_accuracy: 0.3472 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 3.3884 - accuracy: 0.2397 - val_loss: 3.2024 - val_accuracy: 0.3764 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 3.2483 - accuracy: 0.2798 - val_loss: 3.0363 - val_accuracy: 0.3913 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 3.0887 - accuracy: 0.3227 - val_loss: 2.8600 - val_accuracy: 0.4127 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 2.9318 - accuracy: 0.3582 - val_loss: 2.6870 - val_accuracy: 0.4439 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 2.7821 - accuracy: 0.3926 - val_loss: 2.5250 - val_accuracy: 0.4672 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 2.6429 - accuracy: 0.4224 - val_loss: 2.3796 - val_accuracy: 0.4985 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 2.5189 - accuracy: 0.4486 - val_loss: 2.2512 - val_accuracy: 0.5181 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 2.4067 - accuracy: 0.4734 - val_loss: 2.1431 - val_accuracy: 0.5540 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1172/1172 [==============================] - 111s 94ms/step - loss: 2.3163 - accuracy: 0.4939 - val_loss: 2.0518 - val_accuracy: 0.5884 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1172/1172 [==============================] - 99s 85ms/step - loss: 2.2321 - accuracy: 0.5140 - val_loss: 1.9737 - val_accuracy: 0.6257 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1172/1172 [==============================] - 97s 82ms/step - loss: 2.1553 - accuracy: 0.5295 - val_loss: 1.9083 - val_accuracy: 0.6442 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 2.0897 - accuracy: 0.5474 - val_loss: 1.8520 - val_accuracy: 0.6472 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 2.0307 - accuracy: 0.5611 - val_loss: 1.8033 - val_accuracy: 0.6603 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.9777 - accuracy: 0.5739 - val_loss: 1.7642 - val_accuracy: 0.6641 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.9315 - accuracy: 0.5867 - val_loss: 1.7250 - val_accuracy: 0.6678 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.8879 - accuracy: 0.5972 - val_loss: 1.6928 - val_accuracy: 0.6694 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.8540 - accuracy: 0.6074 - val_loss: 1.6632 - val_accuracy: 0.6721 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.8167 - accuracy: 0.6170 - val_loss: 1.6362 - val_accuracy: 0.6759 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.7766 - accuracy: 0.6262 - val_loss: 1.6115 - val_accuracy: 0.6792 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.7473 - accuracy: 0.6324 - val_loss: 1.5888 - val_accuracy: 0.6862 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "1172/1172 [==============================] - 98s 83ms/step - loss: 1.7245 - accuracy: 0.6405 - val_loss: 1.5687 - val_accuracy: 0.6900 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 1.6913 - accuracy: 0.6473 - val_loss: 1.5501 - val_accuracy: 0.6920 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.6736 - accuracy: 0.6558 - val_loss: 1.5320 - val_accuracy: 0.6988 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "1172/1172 [==============================] - 107s 92ms/step - loss: 1.6439 - accuracy: 0.6616 - val_loss: 1.5171 - val_accuracy: 0.7005 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.6234 - accuracy: 0.6672 - val_loss: 1.5005 - val_accuracy: 0.7032 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.5989 - accuracy: 0.6735 - val_loss: 1.4860 - val_accuracy: 0.7033 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.5800 - accuracy: 0.6785 - val_loss: 1.4728 - val_accuracy: 0.7073 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.5622 - accuracy: 0.6840 - val_loss: 1.4597 - val_accuracy: 0.7092 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "1172/1172 [==============================] - 97s 82ms/step - loss: 1.5396 - accuracy: 0.6881 - val_loss: 1.4469 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.5203 - accuracy: 0.6965 - val_loss: 1.4359 - val_accuracy: 0.7191 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "1172/1172 [==============================] - 97s 82ms/step - loss: 1.5080 - accuracy: 0.6989 - val_loss: 1.4235 - val_accuracy: 0.7220 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.4899 - accuracy: 0.7036 - val_loss: 1.4132 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.4738 - accuracy: 0.7059 - val_loss: 1.4021 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.4600 - accuracy: 0.7111 - val_loss: 1.3919 - val_accuracy: 0.7312 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.4436 - accuracy: 0.7134 - val_loss: 1.3822 - val_accuracy: 0.7332 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.4271 - accuracy: 0.7182 - val_loss: 1.3733 - val_accuracy: 0.7354 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.4186 - accuracy: 0.7213 - val_loss: 1.3627 - val_accuracy: 0.7386 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "1172/1172 [==============================] - 108s 92ms/step - loss: 1.4041 - accuracy: 0.7249 - val_loss: 1.3546 - val_accuracy: 0.7393 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.3925 - accuracy: 0.7271 - val_loss: 1.3466 - val_accuracy: 0.7406 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.3778 - accuracy: 0.7329 - val_loss: 1.3374 - val_accuracy: 0.7430 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 1.3671 - accuracy: 0.7341 - val_loss: 1.3299 - val_accuracy: 0.7436 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.3561 - accuracy: 0.7355 - val_loss: 1.3219 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.3475 - accuracy: 0.7389 - val_loss: 1.3145 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.3335 - accuracy: 0.7404 - val_loss: 1.3083 - val_accuracy: 0.7496 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.3215 - accuracy: 0.7443 - val_loss: 1.3020 - val_accuracy: 0.7502 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.3123 - accuracy: 0.7467 - val_loss: 1.2942 - val_accuracy: 0.7525 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.3047 - accuracy: 0.7479 - val_loss: 1.2878 - val_accuracy: 0.7532 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.2946 - accuracy: 0.7507 - val_loss: 1.2820 - val_accuracy: 0.7544 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "1172/1172 [==============================] - 101s 87ms/step - loss: 1.2852 - accuracy: 0.7537 - val_loss: 1.2766 - val_accuracy: 0.7558 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.2740 - accuracy: 0.7540 - val_loss: 1.2704 - val_accuracy: 0.7580 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "1172/1172 [==============================] - 100s 86ms/step - loss: 1.2662 - accuracy: 0.7566 - val_loss: 1.2646 - val_accuracy: 0.7593 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.2581 - accuracy: 0.7590 - val_loss: 1.2579 - val_accuracy: 0.7614 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.2494 - accuracy: 0.7596 - val_loss: 1.2529 - val_accuracy: 0.7618 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.2423 - accuracy: 0.7629 - val_loss: 1.2474 - val_accuracy: 0.7624 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.2353 - accuracy: 0.7642 - val_loss: 1.2428 - val_accuracy: 0.7637 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.2332 - accuracy: 0.7650 - val_loss: 1.2365 - val_accuracy: 0.7646 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.2225 - accuracy: 0.7677 - val_loss: 1.2334 - val_accuracy: 0.7665 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.2157 - accuracy: 0.7680 - val_loss: 1.2280 - val_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "1172/1172 [==============================] - 94s 80ms/step - loss: 1.2083 - accuracy: 0.7706 - val_loss: 1.2238 - val_accuracy: 0.7687 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "1172/1172 [==============================] - 94s 80ms/step - loss: 1.2037 - accuracy: 0.7710 - val_loss: 1.2193 - val_accuracy: 0.7686 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.1970 - accuracy: 0.7726 - val_loss: 1.2144 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.1905 - accuracy: 0.7749 - val_loss: 1.2107 - val_accuracy: 0.7727 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.1815 - accuracy: 0.7763 - val_loss: 1.2075 - val_accuracy: 0.7737 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.1774 - accuracy: 0.7783 - val_loss: 1.2022 - val_accuracy: 0.7747 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.1738 - accuracy: 0.7790 - val_loss: 1.1987 - val_accuracy: 0.7752 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.1701 - accuracy: 0.7799 - val_loss: 1.1946 - val_accuracy: 0.7756 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "1172/1172 [==============================] - 118s 100ms/step - loss: 1.1613 - accuracy: 0.7817 - val_loss: 1.1904 - val_accuracy: 0.7766 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "1172/1172 [==============================] - 107s 92ms/step - loss: 1.1584 - accuracy: 0.7810 - val_loss: 1.1882 - val_accuracy: 0.7766 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.1535 - accuracy: 0.7851 - val_loss: 1.1847 - val_accuracy: 0.7773 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "1172/1172 [==============================] - 123s 105ms/step - loss: 1.1462 - accuracy: 0.7852 - val_loss: 1.1807 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "1172/1172 [==============================] - 149s 127ms/step - loss: 1.1414 - accuracy: 0.7863 - val_loss: 1.1775 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "1172/1172 [==============================] - 150s 128ms/step - loss: 1.1387 - accuracy: 0.7866 - val_loss: 1.1732 - val_accuracy: 0.7783 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "1172/1172 [==============================] - 145s 124ms/step - loss: 1.1336 - accuracy: 0.7880 - val_loss: 1.1712 - val_accuracy: 0.7786 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "1172/1172 [==============================] - 147s 126ms/step - loss: 1.1292 - accuracy: 0.7875 - val_loss: 1.1674 - val_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "1172/1172 [==============================] - 145s 124ms/step - loss: 1.1219 - accuracy: 0.7903 - val_loss: 1.1652 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "1172/1172 [==============================] - 148s 126ms/step - loss: 1.1205 - accuracy: 0.7906 - val_loss: 1.1617 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "1172/1172 [==============================] - 147s 126ms/step - loss: 1.1158 - accuracy: 0.7920 - val_loss: 1.1585 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "1172/1172 [==============================] - 153s 131ms/step - loss: 1.1152 - accuracy: 0.7920 - val_loss: 1.1561 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "1172/1172 [==============================] - 156s 133ms/step - loss: 1.1094 - accuracy: 0.7918 - val_loss: 1.1526 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "1172/1172 [==============================] - 158s 135ms/step - loss: 1.1068 - accuracy: 0.7933 - val_loss: 1.1500 - val_accuracy: 0.7824 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "1172/1172 [==============================] - 155s 132ms/step - loss: 1.1007 - accuracy: 0.7952 - val_loss: 1.1483 - val_accuracy: 0.7831 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "1172/1172 [==============================] - 155s 132ms/step - loss: 1.0983 - accuracy: 0.7953 - val_loss: 1.1441 - val_accuracy: 0.7845 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "1172/1172 [==============================] - 157s 134ms/step - loss: 1.0969 - accuracy: 0.7969 - val_loss: 1.1424 - val_accuracy: 0.7847 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "1172/1172 [==============================] - 157s 134ms/step - loss: 1.0924 - accuracy: 0.7974 - val_loss: 1.1410 - val_accuracy: 0.7848 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "1172/1172 [==============================] - 134s 115ms/step - loss: 1.0889 - accuracy: 0.7974 - val_loss: 1.1377 - val_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0829 - accuracy: 0.7983 - val_loss: 1.1367 - val_accuracy: 0.7849 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.0773 - accuracy: 0.7996 - val_loss: 1.1331 - val_accuracy: 0.7854 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0775 - accuracy: 0.7995 - val_loss: 1.1313 - val_accuracy: 0.7854 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0780 - accuracy: 0.8003 - val_loss: 1.1290 - val_accuracy: 0.7855 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0731 - accuracy: 0.8006 - val_loss: 1.1267 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0704 - accuracy: 0.8012 - val_loss: 1.1250 - val_accuracy: 0.7858 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0695 - accuracy: 0.8011 - val_loss: 1.1223 - val_accuracy: 0.7860 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0649 - accuracy: 0.8024 - val_loss: 1.1216 - val_accuracy: 0.7860 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0618 - accuracy: 0.8029 - val_loss: 1.1192 - val_accuracy: 0.7861 - lr: 0.0010\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0598 - accuracy: 0.8030 - val_loss: 1.1183 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "1172/1172 [==============================] - 100s 86ms/step - loss: 1.0548 - accuracy: 0.8043 - val_loss: 1.1157 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0544 - accuracy: 0.8039 - val_loss: 1.1125 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0502 - accuracy: 0.8052 - val_loss: 1.1114 - val_accuracy: 0.7867 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "1172/1172 [==============================] - 95s 81ms/step - loss: 1.0512 - accuracy: 0.8058 - val_loss: 1.1093 - val_accuracy: 0.7867 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.0474 - accuracy: 0.8056 - val_loss: 1.1079 - val_accuracy: 0.7866 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.0422 - accuracy: 0.8061 - val_loss: 1.1059 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.0408 - accuracy: 0.8070 - val_loss: 1.1045 - val_accuracy: 0.7873 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0386 - accuracy: 0.8070 - val_loss: 1.1026 - val_accuracy: 0.7874 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "1172/1172 [==============================] - 96s 82ms/step - loss: 1.0380 - accuracy: 0.8077 - val_loss: 1.1008 - val_accuracy: 0.7883 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0372 - accuracy: 0.8074 - val_loss: 1.0987 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.0304 - accuracy: 0.8079 - val_loss: 1.0987 - val_accuracy: 0.7876 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.8090\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0329 - accuracy: 0.8090 - val_loss: 1.0961 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0316 - accuracy: 0.8088 - val_loss: 1.0949 - val_accuracy: 0.7882 - lr: 5.0000e-04\n",
      "Epoch 116/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 1.0264 - accuracy: 0.8085 - val_loss: 1.0942 - val_accuracy: 0.7883 - lr: 5.0000e-04\n",
      "Epoch 117/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0271 - accuracy: 0.8090 - val_loss: 1.0931 - val_accuracy: 0.7885 - lr: 5.0000e-04\n",
      "Epoch 118/300\n",
      "1172/1172 [==============================] - 119s 101ms/step - loss: 1.0261 - accuracy: 0.8093 - val_loss: 1.0923 - val_accuracy: 0.7883 - lr: 5.0000e-04\n",
      "Epoch 119/300\n",
      "1172/1172 [==============================] - 113s 97ms/step - loss: 1.0212 - accuracy: 0.8099 - val_loss: 1.0921 - val_accuracy: 0.7882 - lr: 5.0000e-04\n",
      "Epoch 120/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.8094\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1172/1172 [==============================] - 120s 102ms/step - loss: 1.0242 - accuracy: 0.8094 - val_loss: 1.0911 - val_accuracy: 0.7884 - lr: 5.0000e-04\n",
      "Epoch 121/300\n",
      "1172/1172 [==============================] - 121s 103ms/step - loss: 1.0257 - accuracy: 0.8095 - val_loss: 1.0905 - val_accuracy: 0.7884 - lr: 2.5000e-04\n",
      "Epoch 122/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0224 - accuracy: 0.8103 - val_loss: 1.0901 - val_accuracy: 0.7885 - lr: 2.5000e-04\n",
      "Epoch 123/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0230 - accuracy: 0.8100\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.0230 - accuracy: 0.8100 - val_loss: 1.0897 - val_accuracy: 0.7885 - lr: 2.5000e-04\n",
      "Epoch 124/300\n",
      "1172/1172 [==============================] - 98s 83ms/step - loss: 1.0197 - accuracy: 0.8099 - val_loss: 1.0896 - val_accuracy: 0.7885 - lr: 1.2500e-04\n",
      "Epoch 125/300\n",
      "1172/1172 [==============================] - 107s 92ms/step - loss: 1.0189 - accuracy: 0.8104 - val_loss: 1.0896 - val_accuracy: 0.7885 - lr: 1.2500e-04\n",
      "Epoch 126/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0215 - accuracy: 0.8110\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.0215 - accuracy: 0.8110 - val_loss: 1.0894 - val_accuracy: 0.7885 - lr: 1.2500e-04\n",
      "Epoch 127/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0231 - accuracy: 0.8100 - val_loss: 1.0892 - val_accuracy: 0.7885 - lr: 6.2500e-05\n",
      "Epoch 128/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0196 - accuracy: 0.8100 - val_loss: 1.0891 - val_accuracy: 0.7885 - lr: 6.2500e-05\n",
      "Epoch 129/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0191 - accuracy: 0.8096\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0191 - accuracy: 0.8096 - val_loss: 1.0890 - val_accuracy: 0.7885 - lr: 6.2500e-05\n",
      "Epoch 130/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0223 - accuracy: 0.8099 - val_loss: 1.0890 - val_accuracy: 0.7886 - lr: 3.1250e-05\n",
      "Epoch 131/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0200 - accuracy: 0.8093 - val_loss: 1.0889 - val_accuracy: 0.7886 - lr: 3.1250e-05\n",
      "Epoch 132/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0210 - accuracy: 0.8100\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0210 - accuracy: 0.8100 - val_loss: 1.0889 - val_accuracy: 0.7886 - lr: 3.1250e-05\n",
      "Epoch 133/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0185 - accuracy: 0.8100 - val_loss: 1.0888 - val_accuracy: 0.7886 - lr: 1.5625e-05\n",
      "Epoch 134/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0201 - accuracy: 0.8097 - val_loss: 1.0888 - val_accuracy: 0.7886 - lr: 1.5625e-05\n",
      "Epoch 135/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0238 - accuracy: 0.8095 - val_loss: 1.0888 - val_accuracy: 0.7886 - lr: 1.5625e-05\n",
      "Epoch 136/300\n",
      "1172/1172 [==============================] - ETA: 0s - loss: 1.0209 - accuracy: 0.8107\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.0209 - accuracy: 0.8107 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.5625e-05\n",
      "Epoch 137/300\n",
      "1172/1172 [==============================] - 108s 92ms/step - loss: 1.0210 - accuracy: 0.8106 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 138/300\n",
      "1172/1172 [==============================] - 118s 100ms/step - loss: 1.0206 - accuracy: 0.8098 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 139/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0207 - accuracy: 0.8098 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 140/300\n",
      "1172/1172 [==============================] - 111s 94ms/step - loss: 1.0177 - accuracy: 0.8103 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 141/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0215 - accuracy: 0.8099 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 142/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0198 - accuracy: 0.8101 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 143/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0195 - accuracy: 0.8099 - val_loss: 1.0887 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 144/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0218 - accuracy: 0.8102 - val_loss: 1.0886 - val_accuracy: 0.7886 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/300\n",
      "1172/1172 [==============================] - 112s 96ms/step - loss: 1.0240 - accuracy: 0.8092 - val_loss: 1.0886 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 146/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0215 - accuracy: 0.8099 - val_loss: 1.0886 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 147/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0199 - accuracy: 0.8098 - val_loss: 1.0886 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 148/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0196 - accuracy: 0.8105 - val_loss: 1.0886 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 149/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0204 - accuracy: 0.8097 - val_loss: 1.0885 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 150/300\n",
      "1172/1172 [==============================] - 97s 82ms/step - loss: 1.0189 - accuracy: 0.8110 - val_loss: 1.0885 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 151/300\n",
      "1172/1172 [==============================] - 97s 83ms/step - loss: 1.0200 - accuracy: 0.8109 - val_loss: 1.0885 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 152/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0204 - accuracy: 0.8101 - val_loss: 1.0885 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 153/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0200 - accuracy: 0.8099 - val_loss: 1.0885 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 154/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0199 - accuracy: 0.8099 - val_loss: 1.0885 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
      "Epoch 155/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0212 - accuracy: 0.8104 - val_loss: 1.0885 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0211 - accuracy: 0.8102 - val_loss: 1.0884 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 1.0228 - accuracy: 0.8098 - val_loss: 1.0884 - val_accuracy: 0.7887 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0215 - accuracy: 0.8107 - val_loss: 1.0884 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0189 - accuracy: 0.8099 - val_loss: 1.0884 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0184 - accuracy: 0.8108 - val_loss: 1.0884 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "1172/1172 [==============================] - 110s 93ms/step - loss: 1.0201 - accuracy: 0.8100 - val_loss: 1.0884 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "1172/1172 [==============================] - 117s 100ms/step - loss: 1.0209 - accuracy: 0.8106 - val_loss: 1.0884 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0224 - accuracy: 0.8104 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0235 - accuracy: 0.8100 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0199 - accuracy: 0.8104 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0209 - accuracy: 0.8104 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0210 - accuracy: 0.8100 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0194 - accuracy: 0.8108 - val_loss: 1.0883 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 1.0226 - accuracy: 0.8094 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.0202 - accuracy: 0.8100 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0196 - accuracy: 0.8110 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "1172/1172 [==============================] - 113s 97ms/step - loss: 1.0234 - accuracy: 0.8102 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "1172/1172 [==============================] - 112s 96ms/step - loss: 1.0200 - accuracy: 0.8110 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0209 - accuracy: 0.8103 - val_loss: 1.0882 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0226 - accuracy: 0.8099 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0232 - accuracy: 0.8090 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 1.0215 - accuracy: 0.8095 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0212 - accuracy: 0.8092 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0203 - accuracy: 0.8105 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "1172/1172 [==============================] - 118s 100ms/step - loss: 1.0196 - accuracy: 0.8105 - val_loss: 1.0881 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0218 - accuracy: 0.8097 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0178 - accuracy: 0.8106 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0199 - accuracy: 0.8099 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0219 - accuracy: 0.8104 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0198 - accuracy: 0.8103 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0197 - accuracy: 0.8094 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "1172/1172 [==============================] - 112s 96ms/step - loss: 1.0198 - accuracy: 0.8101 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "1172/1172 [==============================] - 111s 94ms/step - loss: 1.0234 - accuracy: 0.8099 - val_loss: 1.0880 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "1172/1172 [==============================] - 118s 101ms/step - loss: 1.0177 - accuracy: 0.8111 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0176 - accuracy: 0.8110 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0202 - accuracy: 0.8105 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0194 - accuracy: 0.8105 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0192 - accuracy: 0.8109 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 194/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0197 - accuracy: 0.8106 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0192 - accuracy: 0.8109 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 1.0181 - accuracy: 0.8102 - val_loss: 1.0879 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0196 - accuracy: 0.8100 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0196 - accuracy: 0.8095 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0176 - accuracy: 0.8104 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "1172/1172 [==============================] - 98s 83ms/step - loss: 1.0215 - accuracy: 0.8099 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0203 - accuracy: 0.8109 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0201 - accuracy: 0.8105 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0173 - accuracy: 0.8107 - val_loss: 1.0878 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0196 - accuracy: 0.8100 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0180 - accuracy: 0.8099 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0203 - accuracy: 0.8106 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0195 - accuracy: 0.8110 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0194 - accuracy: 0.8099 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "1172/1172 [==============================] - 103s 87ms/step - loss: 1.0178 - accuracy: 0.8108 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0191 - accuracy: 0.8104 - val_loss: 1.0877 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0219 - accuracy: 0.8104 - val_loss: 1.0876 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0208 - accuracy: 0.8098 - val_loss: 1.0876 - val_accuracy: 0.7888 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0190 - accuracy: 0.8099 - val_loss: 1.0876 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0185 - accuracy: 0.8105 - val_loss: 1.0876 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0189 - accuracy: 0.8099 - val_loss: 1.0876 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "1172/1172 [==============================] - 97s 82ms/step - loss: 1.0201 - accuracy: 0.8107 - val_loss: 1.0876 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0191 - accuracy: 0.8112 - val_loss: 1.0875 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 1.0215 - accuracy: 0.8096 - val_loss: 1.0875 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0165 - accuracy: 0.8111 - val_loss: 1.0875 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0212 - accuracy: 0.8101 - val_loss: 1.0875 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0191 - accuracy: 0.8111 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0170 - accuracy: 0.8107 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "1172/1172 [==============================] - 108s 93ms/step - loss: 1.0194 - accuracy: 0.8108 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0186 - accuracy: 0.8106 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0200 - accuracy: 0.8105 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0190 - accuracy: 0.8103 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0216 - accuracy: 0.8101 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0195 - accuracy: 0.8109 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "1172/1172 [==============================] - 106s 91ms/step - loss: 1.0183 - accuracy: 0.8106 - val_loss: 1.0874 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0169 - accuracy: 0.8108 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0196 - accuracy: 0.8109 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0187 - accuracy: 0.8108 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "1172/1172 [==============================] - 113s 96ms/step - loss: 1.0177 - accuracy: 0.8098 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "1172/1172 [==============================] - 118s 101ms/step - loss: 1.0168 - accuracy: 0.8105 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0170 - accuracy: 0.8103 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0177 - accuracy: 0.8111 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.0200 - accuracy: 0.8099 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0175 - accuracy: 0.8106 - val_loss: 1.0873 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "1172/1172 [==============================] - 103s 87ms/step - loss: 1.0184 - accuracy: 0.8103 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0196 - accuracy: 0.8103 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0198 - accuracy: 0.8100 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0202 - accuracy: 0.8106 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0165 - accuracy: 0.8099 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0174 - accuracy: 0.8109 - val_loss: 1.0872 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0179 - accuracy: 0.8107 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0215 - accuracy: 0.8106 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0187 - accuracy: 0.8103 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0203 - accuracy: 0.8103 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "1172/1172 [==============================] - 106s 90ms/step - loss: 1.0190 - accuracy: 0.8104 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0183 - accuracy: 0.8118 - val_loss: 1.0871 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0192 - accuracy: 0.8106 - val_loss: 1.0870 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "1172/1172 [==============================] - 98s 84ms/step - loss: 1.0163 - accuracy: 0.8108 - val_loss: 1.0870 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0182 - accuracy: 0.8109 - val_loss: 1.0870 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0183 - accuracy: 0.8108 - val_loss: 1.0870 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0211 - accuracy: 0.8103 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0179 - accuracy: 0.8094 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0204 - accuracy: 0.8101 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0175 - accuracy: 0.8109 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0170 - accuracy: 0.8105 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0205 - accuracy: 0.8114 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "1172/1172 [==============================] - 105s 89ms/step - loss: 1.0200 - accuracy: 0.8101 - val_loss: 1.0869 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "1172/1172 [==============================] - 112s 95ms/step - loss: 1.0200 - accuracy: 0.8104 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "1172/1172 [==============================] - 116s 99ms/step - loss: 1.0173 - accuracy: 0.8107 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0195 - accuracy: 0.8103 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "1172/1172 [==============================] - 108s 93ms/step - loss: 1.0175 - accuracy: 0.8098 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0184 - accuracy: 0.8107 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0168 - accuracy: 0.8109 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0173 - accuracy: 0.8110 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "1172/1172 [==============================] - 103s 88ms/step - loss: 1.0182 - accuracy: 0.8110 - val_loss: 1.0868 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "1172/1172 [==============================] - 99s 84ms/step - loss: 1.0202 - accuracy: 0.8106 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0161 - accuracy: 0.8101 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0169 - accuracy: 0.8106 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "1172/1172 [==============================] - 107s 91ms/step - loss: 1.0191 - accuracy: 0.8111 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0188 - accuracy: 0.8115 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "1172/1172 [==============================] - 100s 85ms/step - loss: 1.0196 - accuracy: 0.8114 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "1172/1172 [==============================] - 101s 86ms/step - loss: 1.0189 - accuracy: 0.8099 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "1172/1172 [==============================] - 102s 87ms/step - loss: 1.0196 - accuracy: 0.8110 - val_loss: 1.0867 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "1172/1172 [==============================] - 108s 92ms/step - loss: 1.0212 - accuracy: 0.8108 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0192 - accuracy: 0.8107 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "1172/1172 [==============================] - 114s 97ms/step - loss: 1.0196 - accuracy: 0.8105 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "1172/1172 [==============================] - 114s 98ms/step - loss: 1.0168 - accuracy: 0.8109 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "1172/1172 [==============================] - 115s 98ms/step - loss: 1.0187 - accuracy: 0.8105 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0179 - accuracy: 0.8097 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "1172/1172 [==============================] - 112s 96ms/step - loss: 1.0166 - accuracy: 0.8105 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "1172/1172 [==============================] - 111s 94ms/step - loss: 1.0188 - accuracy: 0.8109 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "1172/1172 [==============================] - 105s 90ms/step - loss: 1.0176 - accuracy: 0.8103 - val_loss: 1.0866 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0187 - accuracy: 0.8099 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "1172/1172 [==============================] - 104s 88ms/step - loss: 1.0169 - accuracy: 0.8103 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "1172/1172 [==============================] - 112s 96ms/step - loss: 1.0181 - accuracy: 0.8101 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "1172/1172 [==============================] - 110s 94ms/step - loss: 1.0184 - accuracy: 0.8116 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "1172/1172 [==============================] - 104s 89ms/step - loss: 1.0170 - accuracy: 0.8107 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 113s 97ms/step - loss: 1.0171 - accuracy: 0.8110 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "1172/1172 [==============================] - 114s 98ms/step - loss: 1.0173 - accuracy: 0.8105 - val_loss: 1.0865 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "1172/1172 [==============================] - 111s 95ms/step - loss: 1.0178 - accuracy: 0.8113 - val_loss: 1.0864 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0215 - accuracy: 0.8109 - val_loss: 1.0864 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0178 - accuracy: 0.8099 - val_loss: 1.0864 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0179 - accuracy: 0.8110 - val_loss: 1.0864 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "1172/1172 [==============================] - 110s 93ms/step - loss: 1.0197 - accuracy: 0.8111 - val_loss: 1.0864 - val_accuracy: 0.7890 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "1172/1172 [==============================] - 108s 92ms/step - loss: 1.0173 - accuracy: 0.8103 - val_loss: 1.0864 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "1172/1172 [==============================] - 109s 93ms/step - loss: 1.0143 - accuracy: 0.8108 - val_loss: 1.0863 - val_accuracy: 0.7889 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "BATCH = 64\n",
    "EPOCH = 300\n",
    "\n",
    "# TODO - протестировать запуск на 100+ эпох 1/10 часть датасета (10 тыс изображений)\n",
    "\n",
    "# Set a learning rate reduction\n",
    "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Загружаем в модель размер изображений и количество классов\n",
    "model = main_model(DATASET_SYMBOL_SIZE, len(labels_comparison))\n",
    "\n",
    "# !!! проверить правильно ли заданы параметры в fit !!!\n",
    "start_time = datetime.now()\n",
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=BATCH, epochs=EPOCH)\n",
    "\n",
    "model_name = f'ru_emnist_letters_100k_b{BATCH}_e{EPOCH}.h5'\n",
    "model.save(model_name)\n",
    "\n",
    "runtime = datetime.now() - start_time\n",
    "print(f'Runtime: {runtime}')\n",
    "with open(f'{model_name}.txt', 'w') as f\n",
    "    f.write(f'Runtime = {runtime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e890ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_saved = keras.models.load_model('ru_emnist_letters_100k_b64_e60.h5')\n",
    "\n",
    "def predict_img(model, img):\n",
    "    \n",
    "    # Эти преобразования нужны только для того, чтобы повернуть символы из датасета emnist (там буквы лежат на боку)\n",
    "    # img_arr = np.expand_dims(img, axis=0)\n",
    "    # img_arr = 1 - img_arr/255.0\n",
    "    # img_arr[0] = np.rot90(img_arr[0], 3)\n",
    "    # img_arr[0] = np.fliplr(img_arr[0])\n",
    "    # img_arr = img_arr.reshape((1, 28, 28, 1))\n",
    "    \n",
    "    img = img.reshape((1, 28, 28, 1))     ### 1 Убрать решейп здесь и в функции Часть 2 блока загрузки модели\n",
    "\n",
    "    predict = model.predict(img)\n",
    "    result = np.argmax(predict, axis=1)     # получаем индекс класса с наибольшей предсказанной вероятностью\n",
    "    \n",
    "    #TODO изменить на использование словаря соответствия класса и буквы. сейчас тупо по индексу класса забираю букву\n",
    "    # return chr(emnist_labels[result[0]])\n",
    "    print(labels_symbol[result[0]])\n",
    "    return labels_symbol[result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd32bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# не использую. убрать!\n",
    "def img_to_str(model, word_by_imgs):\n",
    "    s_out = \"\"\n",
    "    \n",
    "    for letter in word_by_imgs:\n",
    "        s_out += predict_img(model, letter)\n",
    "    return s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e8b24ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model just created will be used.\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "в\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "е\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "е\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "р\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "а\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "з\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "н\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "а\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "п\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "о\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "м\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "с\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "т\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "ь\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "м\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "и\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "д\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "е\n",
      "(1, 28, 28)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "А\n",
      "вееразнапомстьмидеА\n"
     ]
    }
   ],
   "source": [
    "word_images_paths = get_files(r'D:\\work\\test_comp_vision\\test_for_MindSet\\pass_temp\\0\\0_a') # тот же текст, на котором учим\n",
    "# word_images_paths = get_files(r\"D:\\work\\test_comp_vision\\test_for_MindSet\\pass_temp\\0\\1\")\n",
    "word_images = []     # сюда собираем список всех картинок для одного слова\n",
    "predicted_word = ''\n",
    "\n",
    "# Если только что занимались созданием модели - будет запущена она. Если нет - будет запущена версия с диска  \n",
    "if 'model' in locals() or 'model' in globals():\n",
    "    print(\"The model just created will be used.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"The Model has not been created in the current session. Loading the saved model.\")\n",
    "        model = keras.models.load_model(MODEL_PATH)\n",
    "    except NameError as ne:\n",
    "        print(ne)\n",
    "    except Exception as e:     # TODO Добавить обработку отсутствия файла\n",
    "        print(e)\n",
    "\n",
    "# TODO - Переписать под использование картинок из кода выше, вместо исползования сохраненных на диск\n",
    "# Либо вынести в отдельную функцию забор картинок из папки, и в отдельную - запуск обработки полноценных изображений\n",
    "for letter_path in word_images_paths:\n",
    "    #word_images.append(cv2.imread(letter_path))\n",
    "    with Image.open(letter_path) as image:       # открываем картинку по ссылке, преобразуем в массив\n",
    "        # img_to_arr = np.asarray(image)           # преобразуем загруженную картинку к необходимой Модели форме\n",
    "        # img_to_arr = np.asarray([img_to_arr])    # требуется именно такое двойное преобразование \n",
    "        img_to_arr = np.asarray([np.asarray(image)])    # ТАК НАДО!!! Такова форма модели, иначе не работает\n",
    "        print(img_to_arr.shape)\n",
    "        #word_images.append(np.asarray(image))\n",
    "        \n",
    "        predicted_word += predict_img(model=model, img=img_to_arr)\n",
    "        \n",
    "        \n",
    "#print(word_images[0])\n",
    "\n",
    "    \n",
    "#predicted_word = img_to_str(model=model_saved, word_by_imgs=word_images)\n",
    "\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7573b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_images = idx.convert_from_file(DATESET_IMG)\n",
    "ds_images[0]\n",
    "im = Image.fromarray(np.uint8(ds_images[0]))\n",
    "#im.show()\n",
    "#im.close()\n",
    "im = Image.open(r\"D:\\work\\test_comp_vision\\test_for_MindSet\\pass_temp\\0\\0\\0-0.jpg\")\n",
    "im.show()\n",
    "im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6382eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
