{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7b56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "#import tensorflow as tf\n",
    "import glob\n",
    "import h5py\n",
    "import idx2numpy as idx\n",
    "import warnings\n",
    "import re\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c87cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#входное разрешение модели\n",
    "IMAGE_HEIGHT = 28 # Height of the input images\n",
    "IMAGE_WIDTH = 28 #Width of the input images\n",
    "# WORK_DIR = r'D:\\work\\\\test_comp_vision\\datasets\\!_lines_w25_parsed_full' #путь к папке с файлами\n",
    "WORK_DIR = r'D:/work/test_comp_vision/datasets/' # путь к рабочей папке\n",
    "DATASET_DIR = r'!_lines_w25_parsed_norm'\n",
    "#DATASET_IDX_IMG = r'D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_images_100k_upper2.idx'\n",
    "#DATASET_IDX_CLS = r'D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_classes_100k_upper2.idx'\n",
    "# DATASET_SIZE = 100000      # какую часть изображений используем для создания датасета. 0 - если нужны все данные\n",
    "DATASET_TRAIN_SIZE = 125000\n",
    "DATASET_VALID_SIZE = 25000\n",
    "DATASET_TEST_SIZE = DATASET_VALID_SIZE\n",
    "# LABELS = '0123456789АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "LABELS = 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'   # for only uppercase letters without '0' and '3' numbers\n",
    "EXPORT_NAME_CSV = '!img_classes_upper2.csv'\n",
    "\n",
    "LAST_PIC = r'10069_b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641a0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'А': 0, 'Б': 1, 'В': 2, 'Г': 3, 'Д': 4, 'Е': 5, 'Ё': 6, 'Ж': 7, 'З': 8, 'И': 9, 'Й': 10, 'К': 11, 'Л': 12, 'М': 13, 'Н': 14, 'О': 15, 'П': 16, 'Р': 17, 'С': 18, 'Т': 19, 'У': 20, 'Ф': 21, 'Х': 22, 'Ц': 23, 'Ч': 24, 'Ш': 25, 'Щ': 26, 'Ъ': 27, 'Ы': 28, 'Ь': 29, 'Э': 30, 'Ю': 31, 'Я': 32}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Структура папок:\n",
    "base_folder\n",
    "    image_0\n",
    "        image_0_0.jpg\n",
    "        image_0_0.txt\n",
    "        image_0_1.jpg\n",
    "        image_0_1.txt\n",
    "        ...\n",
    "    image_1\n",
    "        image_1_0.jpg\n",
    "        image_1_0.txt\n",
    "        image_1_1.jpg\n",
    "        image_1_1.txt\n",
    "        ...\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def labels_to_int(labels=LABELS) -> dict:\n",
    "    # Преобразуем букву в числвой код для создания классов в модели\n",
    "    # TODO - можно вынести этот функционал в препроцессинговый слой модели - layers.StringLookup(output_mode=\"one_hot\")\n",
    "    label_nums = {}\n",
    "    for i, lab in enumerate(labels):\n",
    "        label_nums[lab] = i\n",
    "    print(label_nums)\n",
    "    return label_nums\n",
    "\n",
    "\n",
    "labels_comparison = labels_to_int()     # получаем сопоставление символа к коду из датасета\n",
    "labels_symbol = list(labels_comparison.keys())     # и получаем отдельно список по символам и кодам\n",
    "labels_class = list(labels_comparison.values())\n",
    "\n",
    "\n",
    "# TODO заменить работу с индексами над путями к файлам на нормальную обработку разрешения файлов\n",
    "def get_dataframe(path):\n",
    "    # pattern = r'/^(.+)(\\.[^ .]+)?$/'      # для удаления разрешения из пути к файлу\n",
    "    \n",
    "    symbol_classes = []\n",
    "    for folder in tqdm(os.listdir(path)):\n",
    "        # пропускаем папки с буквой 'а', т.к. там версия текста в нижнем регистре\n",
    "        # if folder[:-1] == 'a' : continue     # В целом эту проверку можно не делать, т.к. в любом случаем пропускаем буквы не из списка LABEL\n",
    "        # TODO добавить ограничение на количество итераций здесь, чтобы не создавать DataSet больше нужного\n",
    "        for img_file in glob.glob(f'{path}/{folder}/*.jpg'):\n",
    "            # TODO заменить на pathlib.stem\n",
    "            txt_file =  f\"{img_file[:-3]}txt\"    # меняем разрешение для открытия текста [:-3]\n",
    "            # print(f'IMG_file: {img_file}\\nTXT_file: {txt_file}')\n",
    "            with open(txt_file, 'r') as f:\n",
    "                try:\n",
    "                    symbol_class = f.read()\n",
    "                except Exception as e:\n",
    "                    print(txt_file)\n",
    "                    continue\n",
    "                # symbol_class = f.read().upper()      # читаем обозначение буквы и приводим ее к верхнему регистру\n",
    "                if symbol_class not in LABELS: continue      # пропускаем все символы, не входящие в искомое множество\n",
    "                \n",
    "            # TODO - проверить без этого преобразования но с использоованием в дальнейшем строки с ведущей r'string'\n",
    "            # или же переписать весь код на использование Pathlib вместо строк с адресом в win-формате\n",
    "            value = (img_file.replace('\\\\', '/'), labels_comparison[symbol_class])  # меняем системный флеш Винды на тот, что понимает Python\n",
    "            symbol_classes.append(value)\n",
    "    column_names = ['image_path', 'class_id']\n",
    "    return pd.DataFrame(symbol_classes, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fe911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_path = WORK_DIR + DATASET_DIR #путь к основной папке\\ndf_text = pd.DataFrame()\\n\\nif DATASET_SIZE > 0:      # если ограничение задано, то используем его при выборке данных\\n    df_text = df_text.append(get_dataframe(base_path)[:DATASET_SIZE])\\nelse:\\n    df_text = df_text.append(get_dataframe(base_path))\\ndf_text\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code block depricated\n",
    "# Creating DataFrame with path to image and class in symbol format\n",
    "\"\"\"\n",
    "base_path = WORK_DIR + DATASET_DIR #путь к основной папке\n",
    "df_text = pd.DataFrame()\n",
    "\n",
    "if DATASET_SIZE > 0:      # если ограничение задано, то используем его при выборке данных\n",
    "    df_text = df_text.append(get_dataframe(base_path)[:DATASET_SIZE])\n",
    "else:\n",
    "    df_text = df_text.append(get_dataframe(base_path))\n",
    "df_text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6481ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 23458/23458 [00:52<00:00, 445.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481098, 2)\n",
      "(125000, 2)\n",
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481093</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481094</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481095</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481096</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481097</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481098 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_path  class_id\n",
       "0       D:/work/test_comp_vision/datasets/!_lines_w25_...         2\n",
       "1       D:/work/test_comp_vision/datasets/!_lines_w25_...         5\n",
       "2       D:/work/test_comp_vision/datasets/!_lines_w25_...         5\n",
       "3       D:/work/test_comp_vision/datasets/!_lines_w25_...        17\n",
       "4       D:/work/test_comp_vision/datasets/!_lines_w25_...         0\n",
       "...                                                   ...       ...\n",
       "481093  D:/work/test_comp_vision/datasets/!_lines_w25_...        28\n",
       "481094  D:/work/test_comp_vision/datasets/!_lines_w25_...         2\n",
       "481095  D:/work/test_comp_vision/datasets/!_lines_w25_...        15\n",
       "481096  D:/work/test_comp_vision/datasets/!_lines_w25_...         4\n",
       "481097  D:/work/test_comp_vision/datasets/!_lines_w25_...         9\n",
       "\n",
       "[481098 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаем DataFrame в котором хранится путь к фалу/изображению и его класс\n",
    "base_path = WORK_DIR + DATASET_DIR #путь к основной папке\n",
    "df_main = get_dataframe(base_path) # сюда получаем весь датасет с числовым классом вместо буквы\n",
    "\n",
    "valid_slice = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE # ограничение для вырезки датасета валидации\n",
    "test_slice = valid_slice + DATASET_TEST_SIZE          # ограничение для вырезки датасета тестирования\n",
    "# test_slice = min(df_main.shape[0], test_slice)      # можно добавить эту проверку\n",
    "\n",
    "df_train = df_main[:DATASET_TRAIN_SIZE]\n",
    "df_valid = df_main[DATASET_TRAIN_SIZE:valid_slice]\n",
    "df_test = df_main[valid_slice:test_slice]\n",
    "\n",
    "print(df_main.shape)\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "# Распределяем даные на 3 датасета\n",
    "#df_train = df_train.append(get_dataframe(base_path)[:DATASET_TRAIN_SIZE])\n",
    "#df_valid = df_valid.append(get_dataframe(base_path)[DATASET_TRAIN_SIZE:valid_slice])\n",
    "#df_test = df_test.append(get_dataframe(base_path)[valid_slice:test_slice])\n",
    "                           \n",
    "#df_images = pd.DataFrame({'image_path':df_text['file_name'],\n",
    "#                   'class_id':[labels_to_int[label] for label in df_text['class']]})\n",
    "# df_images.to_csv(EXPORT_NAME_CSV, index=False)\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d43ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlabels_to_int = {}\\nfor i, label in enumerate(LABELS):\\n    labels_to_int[label] = i\\n    # labels_to_int[i] = label\\nprint(labels_to_int)\\n\\ndf_images = pd.DataFrame({'image_path':df_text['file_name'],\\n                   'class_id':[labels_to_int[label] for label in df_text['class']]})\\n# df_images.to_csv(EXPORT_NAME_CSV, index=False)\\ndf_images\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code block depricated\n",
    "# Преобразуем классы к числовым значениям\n",
    "\"\"\"\n",
    "labels_to_int = {}\n",
    "for i, label in enumerate(LABELS):\n",
    "    labels_to_int[label] = i\n",
    "    # labels_to_int[i] = label\n",
    "print(labels_to_int)\n",
    "\n",
    "df_images = pd.DataFrame({'image_path':df_text['file_name'],\n",
    "                   'class_id':[labels_to_int[label] for label in df_text['class']]})\n",
    "# df_images.to_csv(EXPORT_NAME_CSV, index=False)\n",
    "df_images\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75c6d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/work/test_comp_vision/datasets/!_lines_w25_parsed_norm/10187_b/10187_b_13.jpg\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "row = 2134\n",
    "print(df_train.iloc[row]['image_path'])\n",
    "print(df_train.iloc[row]['class_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059595b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 2)\n",
      "2\n",
      "5\n",
      "5\n",
      "17\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "for i, row in df_train[:5].iterrows():  \n",
    "    print(row['class_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffda75e",
   "metadata": {},
   "source": [
    "## .IDX файл генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e944056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith Image.open(r\"D:\\\\work\\test_comp_vision\\test_for_MindSet\\\\pass_temp\\x00\\x00\\x00-0.jpg\") as image:\\n        print(image.size)\\n        parsed_image = np.asarray(image)\\n        print(parsed_image.shape)\\n        parsed_image2 = np.asarray([parsed_image])\\n        print(parsed_image2.shape)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code block depricated\n",
    "\"\"\"\n",
    "with Image.open(r\"D:\\work\\test_comp_vision\\test_for_MindSet\\pass_temp\\0\\0\\0-0.jpg\") as image:\n",
    "        print(image.size)\n",
    "        parsed_image = np.asarray(image)\n",
    "        print(parsed_image.shape)\n",
    "        parsed_image2 = np.asarray([parsed_image])\n",
    "        print(parsed_image2.shape)\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d05bc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем все изображения в массив np.array()\n",
    "def idx_file_generator(data_frame, file_name: str):\n",
    "    parsed_images = []              # создаем два файла: в одном хранятся изображения в формате np.array\n",
    "    parsed_classes = []             # во втором хранятся классы\n",
    "    print(f\"Общее количество: {data_frame.shape[0]}\")\n",
    "\n",
    "    for i, row in tqdm(data_frame.iterrows()):\n",
    "\n",
    "        with Image.open(row['image_path']) as image:\n",
    "            parsed_images.append(np.asarray(image))  #открываем картинку по ссылке, преобразуем в массив\n",
    "        #print(parsed_images[row[0]].shape)\n",
    "\n",
    "        parsed_classes.append(row['class_id'])\n",
    "        #print(parsed_classes[row[0]])\n",
    "\n",
    "    np_images = np.asarray(parsed_images) \n",
    "    np_classes = np.asarray(parsed_classes)\n",
    "\n",
    "    print(f\"Датасет изображений к сохранению: {np_images.shape}\")\n",
    "    print(f\"Датасет классов к сохранению: {np_classes.shape}\")\n",
    "\n",
    "    idx.convert_to_file(file_name+r'_images.idx', np_images)\n",
    "    idx.convert_to_file(file_name+r'_labels.idx', np_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa16dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество: 125000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125000it [05:18, 392.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений к сохранению: (125000, 28, 28)\n",
      "Датасет классов к сохранению: (125000,)\n",
      "Общее количество: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [01:03, 392.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений к сохранению: (25000, 28, 28)\n",
      "Датасет классов к сохранению: (25000,)\n",
      "Общее количество: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [01:04, 384.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений к сохранению: (25000, 28, 28)\n",
      "Датасет классов к сохранению: (25000,)\n"
     ]
    }
   ],
   "source": [
    "idx_file_generator(data_frame=df_train, file_name=WORK_DIR+f\"{DATASET_DIR}_TRAIN_{df_train.shape[0]}_UPPER_CHAR_FIXED_COLOR_NORM\")\n",
    "idx_file_generator(data_frame=df_valid, file_name=WORK_DIR+f\"{DATASET_DIR}_VALID_{df_valid.shape[0]}_UPPER_CHAR_FIXED_COLOR_NORM\")\n",
    "idx_file_generator(data_frame=df_test, file_name=WORK_DIR+f\"{DATASET_DIR}_TEST_{df_test.shape[0]}_UPPER_CHAR_FIXED_COLOR_NORM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bb1a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений из файла: (100000, 28, 28)\n",
      "Датасет классов из файла: (100000,)\n"
     ]
    }
   ],
   "source": [
    "# images = idx.convert_from_file(DATASET_IDX_IMG)\n",
    "# classes = idx.convert_from_file(DATASET_IDX_CLS)\n",
    "\n",
    "# print(f\"Датасет изображений из файла: {images.shape}\")\n",
    "# print(f\"Датасет классов из файла: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecb042",
   "metadata": {},
   "source": [
    "## .H5 файл генератор (не используем, т.к. проще было пристроить .IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060be524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем файл датасета для обучения детектора\n",
    "#train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "#images_dir = ''\n",
    "\n",
    "#train_labels_filename = EXPORT_NAME_CSV\n",
    "\n",
    "#train_dataset.parse_csv(images_dir=images_dir,\n",
    "#                        labels_filename=train_labels_filename,\n",
    "#                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "#                        #input_format=['image_name', 'class_id'],\n",
    "#                        include_classes='all')\n",
    "\n",
    "#train_dataset.create_hdf5_dataset(file_path=DATASET_H5,\n",
    "#                                  resize=[IMAGE_HEIGHT, IMAGE_WIDTH],\n",
    "#                                  variable_image_size=True,\n",
    "#                                  verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
