{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7b56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "#import tensorflow as tf\n",
    "import glob\n",
    "import h5py\n",
    "import idx2numpy as idx\n",
    "import warnings\n",
    "import re\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "# from progress.bar import IncrementalBar\n",
    "\n",
    "# from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "# import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c87cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#входное разрешение модели\n",
    "IMAGE_HEIGHT = 28 # Height of the input images\n",
    "IMAGE_WIDTH = 28 #Width of the input images\n",
    "WORK_DIR = 'D:\\work\\\\test_comp_vision\\datasets\\!_lines_w25_parsed_full' #путь к папке с файлами\n",
    "# DATASET_H5 = 'D:\\work\\\\test_comp_vision\\datasets\\!_lines_w25_dataset.h5'\n",
    "DATASET_IDX_IMG = r'D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_images_100k_upper2.idx'\n",
    "DATASET_IDX_CLS = r'D:\\work\\test_comp_vision\\datasets\\!_lines_w25_dataset_classes_100k_upper2.idx'\n",
    "DATASET_SIZE = 100000      # какую часть изображений используем для создания датасета. 0 - если нужны все данные\n",
    "# LABELS = '0123456789АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "LABELS = '12456789АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'   # for only uppercase letters without '0' and '3' numbers\n",
    "EXPORT_NAME_CSV = '!img_classes_upper2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641a0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Структура папок:\n",
    "base_folder\n",
    "    image_0\n",
    "        image_0_0.jpg\n",
    "        image_0_0.txt\n",
    "        image_0_1.jpg\n",
    "        image_0_1.txt\n",
    "        ...\n",
    "    image_1\n",
    "        image_1_0.jpg\n",
    "        image_1_0.txt\n",
    "        image_1_1.jpg\n",
    "        image_1_1.txt\n",
    "        ...\n",
    "        \n",
    "\"\"\"\n",
    "# TODO заменить работу с индексами над путями к файлам на нормальную обработку разрешения файлов\n",
    "def get_dataframe(path):\n",
    "    # pattern = r'/^(.+)(\\.[^ .]+)?$/'      # для удаления разрешения из пути к файлу\n",
    "    \n",
    "    symbol_classes = []\n",
    "    for folder in tqdm(os.listdir(path)):\n",
    "        # пропускаем папки с буквой 'а', т.к. там версия текста в нижнем регистре\n",
    "        if folder[:-1] == 'a' : continue     # В целом эту проверку можно не делать, т.к. в любом случаем пропускаем буквы не из списка LABEL\n",
    "        # TODO добавить ограничение на количество итераций здесь, чтобы не создавать DataSet больше нужного\n",
    "        for img_file in glob.glob(f'{path}/{folder}/*.jpg'):\n",
    "            txt_file =  f\"{img_file[:-3]}txt\"    # меняем разрешение для открытия текста [:-3] TODO заменить на pathlib.stem\n",
    "            # print(f'IMG_file: {img_file}\\nTXT_file: {txt_file}')\n",
    "            with open(txt_file, 'r') as f:\n",
    "                symbol_class = f.read()\n",
    "                # symbol_class = f.read().upper()      # читаем обозначение буквы и приводим ее к верхнему регистру\n",
    "                if symbol_class not in LABELS: continue      # пропускаем все символы, не входящие в искомое множество\n",
    "                \n",
    "            # TODO - проверить без этого преобразования но с использоованием в дальнейшем строки с ведущей r'string'\n",
    "            # или же переписать весь код на использование Pathlib вместо строк с адресом в win-формате\n",
    "            value = (img_file.replace('\\\\', '/'), symbol_class)  # меняем системный флеш Винды на тот, что понимает Python\n",
    "            symbol_classes.append(value)\n",
    "    column_names = ['file_name', 'class']\n",
    "    return pd.DataFrame(symbol_classes, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fe911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20172/20172 [00:46<00:00, 435.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>В</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>Е</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>Е</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>Р</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>А</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>О</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>В</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>С</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>Е</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>Т</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_name class\n",
       "0      D:/work/test_comp_vision/datasets/!_lines_w25_...     В\n",
       "1      D:/work/test_comp_vision/datasets/!_lines_w25_...     Е\n",
       "2      D:/work/test_comp_vision/datasets/!_lines_w25_...     Е\n",
       "3      D:/work/test_comp_vision/datasets/!_lines_w25_...     Р\n",
       "4      D:/work/test_comp_vision/datasets/!_lines_w25_...     А\n",
       "...                                                  ...   ...\n",
       "99995  D:/work/test_comp_vision/datasets/!_lines_w25_...     О\n",
       "99996  D:/work/test_comp_vision/datasets/!_lines_w25_...     В\n",
       "99997  D:/work/test_comp_vision/datasets/!_lines_w25_...     С\n",
       "99998  D:/work/test_comp_vision/datasets/!_lines_w25_...     Е\n",
       "99999  D:/work/test_comp_vision/datasets/!_lines_w25_...     Т\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаем DataFrame в котором хранится путь к фалу/изображению и его класс\n",
    "base_path = WORK_DIR #путь к основной папке\n",
    "df_text = pd.DataFrame()\n",
    "\n",
    "if DATASET_SIZE > 0:      # если ограничение задано, то используем его при выборке данных\n",
    "    df_text = df_text.append(get_dataframe(base_path)[:DATASET_SIZE])\n",
    "else:\n",
    "    df_text = df_text.append(get_dataframe(base_path))\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d43ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '4': 2, '5': 3, '6': 4, '7': 5, '8': 6, '9': 7, 'А': 8, 'Б': 9, 'В': 10, 'Г': 11, 'Д': 12, 'Е': 13, 'Ё': 14, 'Ж': 15, 'З': 16, 'И': 17, 'Й': 18, 'К': 19, 'Л': 20, 'М': 21, 'Н': 22, 'О': 23, 'П': 24, 'Р': 25, 'С': 26, 'Т': 27, 'У': 28, 'Ф': 29, 'Х': 30, 'Ц': 31, 'Ч': 32, 'Ш': 33, 'Щ': 34, 'Ъ': 35, 'Ы': 36, 'Ь': 37, 'Э': 38, 'Ю': 39, 'Я': 40}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>D:/work/test_comp_vision/datasets/!_lines_w25_...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path  class_id\n",
       "0      D:/work/test_comp_vision/datasets/!_lines_w25_...        10\n",
       "1      D:/work/test_comp_vision/datasets/!_lines_w25_...        13\n",
       "2      D:/work/test_comp_vision/datasets/!_lines_w25_...        13\n",
       "3      D:/work/test_comp_vision/datasets/!_lines_w25_...        25\n",
       "4      D:/work/test_comp_vision/datasets/!_lines_w25_...         8\n",
       "...                                                  ...       ...\n",
       "99995  D:/work/test_comp_vision/datasets/!_lines_w25_...        23\n",
       "99996  D:/work/test_comp_vision/datasets/!_lines_w25_...        10\n",
       "99997  D:/work/test_comp_vision/datasets/!_lines_w25_...        26\n",
       "99998  D:/work/test_comp_vision/datasets/!_lines_w25_...        13\n",
       "99999  D:/work/test_comp_vision/datasets/!_lines_w25_...        27\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем классы к числовым значениям\n",
    "labels_to_int = {}\n",
    "for i, label in enumerate(LABELS):\n",
    "    labels_to_int[label] = i\n",
    "    # labels_to_int[i] = label\n",
    "print(labels_to_int)\n",
    "\n",
    "df_images = pd.DataFrame({'image_path':df_text['file_name'],\n",
    "                   'class_id':[labels_to_int[label] for label in df_text['class']]})\n",
    "# df_images.to_csv(EXPORT_NAME_CSV, index=False)\n",
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f75c6d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/work/test_comp_vision/datasets/!_lines_w25_parsed_full/10004_b/10004_b_20.jpg\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "row = 134\n",
    "print(df_images.iloc[row]['image_path'])\n",
    "print(df_images.iloc[row]['class_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059595b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n",
      "10\n",
      "13\n",
      "13\n",
      "25\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(df_images.shape)\n",
    "for i, row in df_images[:5].iterrows():  \n",
    "    print(row['class_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffda75e",
   "metadata": {},
   "source": [
    "## .IDX файл генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e944056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with Image.open(r\"D:\\work\\test_comp_vision\\test_for_MindSet\\pass_temp\\0\\0\\0-0.jpg\") as image:\n",
    "        print(image.size)\n",
    "        parsed_image = np.asarray(image)\n",
    "        print(parsed_image.shape)\n",
    "        parsed_image2 = np.asarray([parsed_image])\n",
    "        print(parsed_image2.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05bc9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [04:09, 400.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений к сохранению: (100000, 28, 28)\n",
      "Датасет классов к сохранению: (100000,)\n"
     ]
    }
   ],
   "source": [
    "# преобразуем все изображения в массив np.array()\n",
    "\n",
    "parsed_images = []              # создаем два файла: в одном хранятся изображения в формате np.array\n",
    "parsed_classes = []             # во втором хранятся классы\n",
    "print(f\"Общее количество: {df_images.shape[0]}\")\n",
    "\n",
    "for i, row in tqdm(df_images.iterrows()):\n",
    "    \n",
    "    with Image.open(row['image_path']) as image:\n",
    "        parsed_images.append(np.asarray(image))  #открываем картинку по ссылке, преобразуем в массив\n",
    "    #print(parsed_images[row[0]].shape)\n",
    "    \n",
    "    parsed_classes.append(row['class_id'])\n",
    "    #print(parsed_classes[row[0]])\n",
    "\n",
    "np_images = np.asarray(parsed_images) \n",
    "np_classes = np.asarray(parsed_classes)\n",
    "\n",
    "print(f\"Датасет изображений к сохранению: {np_images.shape}\")\n",
    "print(f\"Датасет классов к сохранению: {np_classes.shape}\")\n",
    "\n",
    "idx.convert_to_file(DATASET_IDX_IMG, np_images)\n",
    "idx.convert_to_file(DATASET_IDX_CLS, np_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bb1a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет изображений из файла: (100000, 28, 28)\n",
      "Датасет классов из файла: (100000,)\n"
     ]
    }
   ],
   "source": [
    "images = idx.convert_from_file(DATASET_IDX_IMG)\n",
    "classes = idx.convert_from_file(DATASET_IDX_CLS)\n",
    "\n",
    "print(f\"Датасет изображений из файла: {images.shape}\")\n",
    "print(f\"Датасет классов из файла: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0925ad3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет классов из файла: (697932,)\n"
     ]
    }
   ],
   "source": [
    "#images = idx.convert_from_file(DATASET_IDX_IMG)\n",
    "#classes = idx.convert_from_file(r\"D:\\work\\test_comp_vision\\datasets\\emnist_gzip\\emnist-byclass-train-labels-idx1-ubyte\")\n",
    "\n",
    "#print(f\"Датасет изображений из файла: {images.shape}\")\n",
    "#print(f\"Датасет классов из файла: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecb042",
   "metadata": {},
   "source": [
    "## .H5 файл генератор (не используем, т.к. проще было пристроить .IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060be524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем файл датасета для обучения детектора\n",
    "#train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "#images_dir = ''\n",
    "\n",
    "#train_labels_filename = EXPORT_NAME_CSV\n",
    "\n",
    "#train_dataset.parse_csv(images_dir=images_dir,\n",
    "#                        labels_filename=train_labels_filename,\n",
    "#                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "#                        #input_format=['image_name', 'class_id'],\n",
    "#                        include_classes='all')\n",
    "\n",
    "#train_dataset.create_hdf5_dataset(file_path=DATASET_H5,\n",
    "#                                  resize=[IMAGE_HEIGHT, IMAGE_WIDTH],\n",
    "#                                  variable_image_size=True,\n",
    "#                                  verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
